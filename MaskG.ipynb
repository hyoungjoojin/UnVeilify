{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNYJlvwxL6UHUV5eLx/aE+P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# MaskG"],"metadata":{"id":"ygpiVgfrzR12"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24-YaifVzTpo","executionInfo":{"status":"ok","timestamp":1700703090054,"user_tz":-540,"elapsed":14919,"user":{"displayName":"MINJI KIM","userId":"10619798487195704567"}},"outputId":"40c43edb-247c-4deb-8171-ddbdd212e004"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.python.keras import layers\n","import os\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","# from tensorflow.python.keras.layers import Dense"],"metadata":{"id":"5eTa_HOC1vNM","executionInfo":{"status":"ok","timestamp":1700704231037,"user_tz":-540,"elapsed":460,"user":{"displayName":"MINJI KIM","userId":"10619798487195704567"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## layer"],"metadata":{"id":"VS3EvGNz2Ryu"}},{"cell_type":"code","source":["class InstanceNormalization(tf.keras.layers.Layer):\n","  \"\"\"Instance Normalization Layer (https://arxiv.org/abs/1607.08022).\"\"\"\n","\n","  def __init__(self, epsilon=1e-5):\n","    super(InstanceNormalization, self).__init__()\n","    self.epsilon = epsilon\n","\n","  def build(self, input_shape):\n","    self.scale = self.add_weight(name='scale',\n","                                 shape=input_shape[-1:],\n","                                 initializer=tf.random_normal_initializer(1., 0.02),\n","                                 trainable=True)\n","\n","    self.offset = self.add_weight(name='offset',\n","                                  shape=input_shape[-1:],\n","                                  initializer='zeros',\n","                                  trainable=True)\n","\n","  def call(self, x):\n","    mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n","    inv = tf.math.rsqrt(variance + self.epsilon)\n","    normalized = (x - mean) * inv\n","    return self.scale * normalized + self.offset\n","\n","\n","def conv_block(filters, size=3, strides=2, dilation_rate=1, norm_type=None, activation='lrelu', downsample=True):\n","    initializer = tf.random_normal_initializer(0., 0.02)\n","\n","    sequential = tf.keras.Sequential()\n","    if downsample:\n","        sequential.add(\n","            tf.keras.layers.Conv2D(filters, size, strides=strides,\n","                                   padding='same', dilation_rate=dilation_rate,\n","                                   kernel_initializer=initializer, use_bias=False))\n","    else:\n","        sequential.add(\n","            tf.keras.layers.Conv2DTranspose(filters, size, strides=strides,\n","                                            padding='same', kernel_initializer=initializer,\n","                                            use_bias=False))\n","        if norm_type is not None:\n","            if norm_type == 'instance':\n","                sequential.add(InstanceNormalization())\n","            elif norm_type == 'batch':\n","                sequential.add(tf.keras.layers.BatchNormalization())\n","\n","        if activation == 'lrelu':\n","            sequential.add(tf.keras.layers.LeakyReLU())\n","        elif activation == 'relu':\n","            sequential.add(tf.keras.layers.ReLU())\n","    return sequential\n","\n","\n","class SE_Block(tf.keras.layers.Layer):\n","    def __init__(self, channels, reduction_ratio=16):\n","        super(SE_Block, self).__init__()\n","        self.channels = channels\n","        self.reduction_ratio = reduction_ratio\n","        self.initializer = tf.random_normal_initializer(0., 0.02)\n","\n","    def build(self, input_shape):\n","        self.global_pooling = tf.keras.layers.GlobalAveragePooling2D()\n","        self.conv1 = tf.keras.layers.Conv2D(filters=self.channels // self.reduction_ratio,\n","                                            kernel_size=1,\n","                                            activation='relu',\n","                                            kernel_initializer=self.initializer)\n","\n","        self.conv2 = tf.keras.layers.Conv2D(filters=self.channels,\n","                                            kernel_size=1,\n","                                            activation='sigmoid',\n","                                            kernel_initializer=self.initializer)\n","\n","    def call(self, inputs):\n","        batch_size = inputs.shape[0]\n","        pooled_inputs = self.global_pooling(inputs)\n","        reshaped_inputs = tf.reshape(pooled_inputs, [batch_size, 1, 1,-1])\n","        conv_output = self.conv1(reshaped_inputs)\n","        conv_output = self.conv2(conv_output)\n","        return tf.math.multiply(inputs, conv_output)\n","\n","\n","class ASPP(tf.keras.layers.Layer):\n","    def __init__(self, channels, rates=[2, 4, 8, 16]):\n","        super(ASPP, self).__init__()\n","        self.channels = channels\n","        self.rates = rates\n","\n","    def build(self, input_shape):\n","        self.conv1x1 =  conv_block(self.channels, size=1, strides=1,\n","                                   norm_type='instance', activation='lrelu')\n","\n","        self.conv3x3_1 = conv_block(self.channels, size=3, strides=1,\n","                                    dilation_rate=self.rates[0],\n","                                    norm_type='instance', activation='lrelu')\n","\n","        self.conv3x3_2 = conv_block(self.channels, size=3, strides=1,\n","                                    dilation_rate=self.rates[1],\n","                                    norm_type='instance', activation='lrelu')\n","\n","        self.conv3x3_3 = conv_block(self.channels, size=3, strides=1,\n","                                    dilation_rate=self.rates[2],\n","                                    norm_type='instance', activation='lrelu')\n","\n","        # self.conv3x3_4 = conv_block(self.channels, size=3, strides=1, dilation_rate=self.rates[3], norm_type='instance', activation='lrelu')\n","\n","        self.global_pooling = tf.keras.layers.GlobalAveragePooling2D()\n","        self.conv1x1_pool = conv_block(self.channels, size=1, strides=1,\n","                                       norm_type='instance', activation='lrelu')\n","\n","        self.concat = tf.keras.layers.Concatenate()\n","        self.conv1x1_concat = conv_block(self.channels, size=1, strides=1,\n","                                         norm_type='instance', activation='lrelu')\n","\n","    def call(self, inputs):\n","        batch_size = inputs.shape[0]\n","        x1 = self.conv1x1(inputs)\n","        x2 = self.conv3x3_1(inputs)\n","        x3 = self.conv3x3_2(inputs)\n","        x4 = self.conv3x3_3(inputs)\n","        # x5 = self.conv3x3_4(inputs)\n","\n","        x5 = self.global_pooling(inputs)\n","        x5 = tf.reshape(x5, [batch_size, 1, 1, -1])\n","        x5 = self.conv1x1_pool(x5)\n","        x5 = tf.image.resize(x5, (inputs.shape[1], inputs.shape[2]))\n","\n","        x = self.concat([x1, x2, x3, x4, x5])\n","        x = self.conv1x1_concat(x)\n","        return x"],"metadata":{"id":"TNskuNW81w7J","executionInfo":{"status":"ok","timestamp":1700703798802,"user_tz":-540,"elapsed":8,"user":{"displayName":"MINJI KIM","userId":"10619798487195704567"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## noise processing"],"metadata":{"id":"lJ5o9Kz43PKt"}},{"cell_type":"code","source":["def noise_processing(generate_image):\n","    \"\"\"\n","    Mask Generator를 통해 나온 Binary 이미지에 Noise 제거\n","    Args:\n","      generate_image : model를 통해 생성된 이미지\n","    Return:\n","      processe가 된 인물 이미지\n","    \"\"\"\n","    generate_image = generate_image.numpy()\n","    batch, height, width  = generate_image.shape[0], generate_image.shape[1], generate_image.shape[2]\n","    generate_image = generate_image[:, :, :, 0]\n","    k = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))\n","    for i in range(batch):\n","        generate_image[i]= cv2.erode(generate_image[i], k)             #  mask Morphology 연산 전처리\n","        generate_image[i] = cv2.dilate(generate_image[i], k)\n","    generate_image = np.where(generate_image >= -0.9, 1, -1)\n","    generate_image = tf.convert_to_tensor(generate_image, dtype=tf.float32)\n","    generate_image = tf.reshape(generate_image, [batch, height, width , 1])\n","    return generate_image\n","\n","def face_training_visualization(model, test_input, mask_map, tar, epoch, step, save_dir='./face32_training'):\n","    \"\"\"\n","    fece model training visualization\n","    Args:\n","        model : Mask Generate model\n","        test_input : input image\n","        mask_map : Mask Generate model out\n","        tar : ground truth image\n","        epoch, step : training epoch, step\n","    \"\"\"\n","\n","    plt.ion()\n","    figure, ax = plt.subplots(figsize=(8,8))\n","\n","    if not os.path.exists(save_dir):\n","      os.mkdir(save_dir)\n","\n","    prediction = model([test_input, mask_map], training=False)\n","    display_list = [test_input[0], tar[0], prediction[0], mask_map[0]]\n","    title = ['Input Image', 'Ground Truth', 'Predicted Image', 'Predicted mask']\n","\n","    for i in range(4):\n","        plt.subplot(1, 4, i+1)\n","        plt.title(title[i])\n","        plt.imshow(display_list[i] * 0.5 + 0.5)\n","        plt.axis('off')\n","    plt.savefig(save_dir+\"/epoch_{epoch}_step_{step}.png\".format(epoch=epoch, step=step))\n","    plt.show()\n","\n","    figure.canvas.draw()\n","    figure.canvas.flush_events()"],"metadata":{"id":"nAGQ3H7O3J3V","executionInfo":{"status":"ok","timestamp":1700704120706,"user_tz":-540,"elapsed":284,"user":{"displayName":"MINJI KIM","userId":"10619798487195704567"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## Prediction"],"metadata":{"id":"CvkaRHFv26jl"}},{"cell_type":"code","source":["class Load_Model():\n","    def __init__(self, mask_model, face_model, mask_checkpoint_dir, face_checkpoint_dir):\n","        self.mask_model = mask_model\n","        self.face_model = face_model\n","\n","        self.mask_checkpoint_dir = mask_checkpoint_dir\n","        self.face_checkpoint_dir = face_checkpoint_dir\n","\n","        self.mask_checkpoint = tf.train.Checkpoint(generator=self.mask_model)\n","        self.face_checkpoint = tf.train.Checkpoint(generator=self.face_model)\n","\n","        self.mask_checkpoint.restore(tf.train.latest_checkpoint(self.mask_checkpoint_dir))\n","        self.face_checkpoint.restore(tf.train.latest_checkpoint(self.face_checkpoint_dir))\n","\n","    def predict(self, img_path, img_size=256):\n","        img = plt.imread(img_path)\n","        if img_path.endswith('.jpg') or img_path.endswith('.PNG'):\n","            img = img * 255.0\n","        img = tf.keras.preprocessing.image.img_to_array(img)\n","        img = tf.image.resize(img, [img_size, img_size],\n","                            method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","        img = tf.reshape(img, [1, img_size, img_size, 3])\n","        img = tf.cast(img, tf.float32)\n","        img =  (img / 127.5) - 1\n","\n","        mask = self.mask_model(img, training=False)\n","        mask = noise_processing(mask)\n","        pred = self.face_model([img, mask], training=False)\n","\n","        plt.figure(figsize=(8,8))\n","        plt.title('Prediction Image')\n","        plt.imshow(pred[0] * 0.5 + 0.5)\n","        plt.axis('off')\n","        plt.show()"],"metadata":{"id":"ram9lAO-24-h","executionInfo":{"status":"ok","timestamp":1700704405785,"user_tz":-540,"elapsed":285,"user":{"displayName":"MINJI KIM","userId":"10619798487195704567"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Mask G and Face G"],"metadata":{"id":"3auqZ_ID2VGe"}},{"cell_type":"code","source":["class Mask_G(tf.keras.Model):\n","    def __init__(self, filters=32, block_num=5):\n","        super(Mask_G, self).__init__()\n","        self.filters = filters\n","        self.block_num = block_num\n","        self.initializer = tf.random_normal_initializer(0., 0.02)\n","        self.encoders = []\n","        self.decoders = []\n","\n","    def build(self, input_shape):\n","        # Encoder layers\n","        for i in range(self.block_num):\n","            norm_type = 'instance' if i != 0 else None\n","            downsample_block = conv_block(self.filters, size=3, strides=2,\n","                                          norm_type=norm_type, activation='lrelu')\n","\n","            self.encoders.append(downsample_block)\n","\n","            self.filters = self.filters*2 if i < 4 else self.filters\n","\n","        self.encoders.append(conv_block(self.filters, size=3, strides=2,\n","                                        norm_type='instance', activation='lrelu'))\n","        # Dencoder layers\n","        for i in range(self.block_num):\n","            self.decoders.append(conv_block(self.filters, size=3, strides=2,\n","                                            norm_type='instance', activation='relu',\n","                                            downsample=False))\n","            self.filters//=2\n","\n","        self.out = layers.Conv2DTranspose(1,\n","                                          kernel_size=3,\n","                                          strides=2,\n","                                          padding='same',\n","                                          kernel_initializer=self.initializer,\n","                                          use_bias=False)\n","\n","    def call(self, inputs, training=False):\n","        x = inputs\n","        encoders_outputs = []\n","        for i, block in enumerate(self.encoders):\n","            x = block(x)\n","            if 0 < i < self.block_num:\n","                encoders_outputs.append(x)\n","        for i, block in enumerate(self.decoders):\n","            x = block(x)\n","            if i < self.block_num-1:\n","                x = tf.concat([encoders_outputs.pop(), x], -1)\n","        out = self.out(x)\n","\n","        return tf.keras.activations.tanh(out)\n","\n","\n","class Face_G(tf.keras.Model):\n","    def __init__(self, filters=32, block_num=5):\n","        super(Face_G, self).__init__()\n","        self.filters = filters\n","        self.block_num = block_num\n","        self.initializer = tf.random_normal_initializer(0., 0.02)\n","        self.encoders = []\n","        self.decoders = []\n","\n","    def build(self, input_shape):\n","        # Encoder layers\n","        for i in range(self.block_num):\n","            norm_type = 'instance' if i != 0 else None\n","            if i < 3:\n","                downsample_block = [conv_block(self.filters, size=3, strides=2,\n","                                                norm_type=norm_type, activation='lrelu'),\n","                                    SE_Block(self.filters)]\n","                downsample_block = tf.keras.Sequential(downsample_block)\n","            else:\n","                downsample_block = conv_block(self.filters, size=3, strides=2,\n","                                                  norm_type=norm_type, activation='lrelu')\n","\n","            self.encoders.append(downsample_block)\n","\n","            self.filters = self.filters*2 if i < 4 else self.filters\n","\n","        self.encoders.append(ASPP(self.filters))\n","\n","        # Dencoder layers\n","        for i in range(self.block_num):\n","            strides = 1 if i == 0 else 2\n","            self.decoders.append(conv_block(self.filters, size=3, strides=strides,\n","                                            norm_type='instance', activation='relu',\n","                                            downsample=False))\n","            self.filters//=2\n","\n","        self.out = layers.Conv2DTranspose(3,\n","                                          kernel_size=3,\n","                                          strides=2,\n","                                          padding='same',\n","                                          kernel_initializer=self.initializer,\n","                                          use_bias=False)\n","\n","    def call(self, inputs, training=False):\n","        face, mask = inputs[0], inputs[1]\n","        x = tf.concat([face, mask], -1)\n","        encoders_outputs = []\n","        for i, block in enumerate(self.encoders):\n","            x = block(x)\n","            if 0 < i < self.block_num:\n","                encoders_outputs.append(x)\n","        for i, block in enumerate(self.decoders):\n","            x = block(x)\n","            if i < self.block_num-1:\n","                x = tf.concat([encoders_outputs.pop(), x], -1)\n","        out = self.out(x)\n","\n","        return tf.keras.activations.tanh(out)"],"metadata":{"id":"QZN5ou8r2cM7","executionInfo":{"status":"ok","timestamp":1700703884779,"user_tz":-540,"elapsed":4,"user":{"displayName":"MINJI KIM","userId":"10619798487195704567"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["mask_G, face_G = Mask_G(filters=32), Face_G(filters=32)"],"metadata":{"id":"TpzuTISC34hJ","executionInfo":{"status":"ok","timestamp":1700704269961,"user_tz":-540,"elapsed":4,"user":{"displayName":"MINJI KIM","userId":"10619798487195704567"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["test = Load_Model(mask_G, face_G,\n","                  mask_checkpoint_dir='/content/drive/MyDrive/AI_Project/project/NoMask/mask32_checkpoints',\n","                  face_checkpoint_dir='/content/drive/MyDrive/AI_Project/project/NoMask/face_checkpoints')"],"metadata":{"id":"cqzdeidP37ne","executionInfo":{"status":"ok","timestamp":1700704474308,"user_tz":-540,"elapsed":418,"user":{"displayName":"MINJI KIM","userId":"10619798487195704567"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["test.predict('/content/drive/MyDrive/processed/masked_image/0001_0001.png.jpg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"LLrAmYTN4tm9","executionInfo":{"status":"error","timestamp":1700704479498,"user_tz":-540,"elapsed":527,"user":{"displayName":"MINJI KIM","userId":"10619798487195704567"}},"outputId":"5149a07b-518f-4266-a872-9274e90eb7b2"},"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-0334736fef27>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/processed/masked_image/0001_0001.png.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-f8257090a846>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, img_path, img_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m127.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-53daec009c49>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mnorm_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'instance'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             downsample_block = conv_block(self.filters, size=3, strides=2, \n\u001b[0m\u001b[1;32m     15\u001b[0m                                           norm_type=norm_type, activation='lrelu')\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'conv_block' is not defined"]}]}]}